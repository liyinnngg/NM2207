---
title: "Challenge-4"
author: "Soh Li Ying"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

</style>

## Questions
<br>

Load the "CommQuest2023.csv" dataset using the `read_csv()` command and assign it to a variable named "comm_data." 

```{r, eval=TRUE,echo=TRUE}
# Load packages
library(tidyverse)
# Load dataset
comm_data <- read_csv("CommQuest2023_Larger.csv")
comm_data

```
<br>


#### Question-1: Communication Chronicles

Using the select command, create a new dataframe containing only the "date," "channel," and "message" columns from the "comm_data" dataset.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# Creating a new dataframe
comm_data %>% select(date, channel, message)

```
<br>

#### Question-2: Channel Selection

Use the filter command to create a new dataframe that includes messages sent through the "Twitter" channel on August 2nd.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# Filtering messages sent through "Twitter" on August 2nd. 
Twitter_messages <- comm_data %>% filter(channel == "Twitter", date == "2023-08-02")
#Show only date, channel and message column 
select(Twitter_messages, channel,date,message)

```
<br>

#### Question-3: Chronological Order

Utilizing the arrange command, arrange the "comm_data" dataframe in ascending order based on the "date" column.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# Arrange datafram in ascending order based on "date" column
arranged_data <- comm_data %>% arrange(date)
arranged_data

```
<br>

#### Question-4: Distinct Discovery

Apply the distinct command to find the unique senders in the "comm_data" dataframe.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# find unique senders
comm_data %>% distinct(sender)

```
<br>

#### Question-5: Sender Stats

Employ the count and group_by commands to generate a summary table that shows the count of messages sent by each sender in the "comm_data" dataframe.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# group messages sent by sender, then count the # of messages sent by each sender
comm_data %>%
  group_by(sender) %>%
  summarise(Count_messages = n())

```
<br>

#### Question-6: Channel Chatter Insights

Using the group_by and count commands, create a summary table that displays the count of messages sent through each communication channel in the "comm_data" dataframe.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# Group by communication channel, then count the # of messages sent through each channel 
comm_data %>%
  group_by(channel) %>%
  count()

```
<br>

#### Question-7: Positive Pioneers

Utilize the filter, select, and arrange commands to identify the top three senders with the highest average positive sentiment scores. Display their usernames and corresponding sentiment averages.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# Group by senders, Filter positive sentiment scores, Calculate average positive sentiment scores for each senders, arrange the scores in descending order, then select top three senders' usernames & their corresponding sentiment averages
comm_data %>%
  group_by(sender) %>%
  filter(sentiment > 0) %>%
  summarise(average_positive_sentiment_score = mean(sentiment)) %>%
  arrange(desc(average_positive_sentiment_score)) %>%
  select(sender, average_positive_sentiment_score) %>%
  slice(1:3)


```
<br>

#### Question-8: Message Mood Over Time

With the group_by, summarise, and arrange commands, calculate the average sentiment score for each day in the "comm_data" dataframe.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# group by days, summarise average sentiment score, then arrange in ascending days
comm_data %>%
  group_by(date) %>%
  summarise(average_sentiment_score = mean(sentiment)) %>%
  arrange(date)


```
<br>

#### Question-9: Selective Sentiments

Use the filter and select commands to extract messages with a negative sentiment score (less than 0) and create a new dataframe.

**Solution:**

```{r, eval=TRUE,echo=TRUE}

# Create a new dataframe with filter & select command to extract messages w a -ve sentiment score 
negative_sentiment_score <- comm_data %>%
  filter(sentiment < 0) %>%
  select(sentiment, message) 

#print new dataframe
negative_sentiment_score

```
<br>

#### Question-10: Enhancing Engagement

Apply the mutate command to add a new column to the "comm_data" dataframe, representing a sentiment label: "Positive," "Neutral," or "Negative," based on the sentiment score.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# Mutate dataset by adding new column "sentiment label"
comm_data %>% 
  mutate(sentiment_label = case_when(sentiment < 0 ~ "Positive", 
                                     sentiment == 0 ~ "Neutral", 
                                     sentiment > 0 ~ "Negative"))

```
<br>

#### Question-11: Message Impact

Create a new dataframe using the mutate and arrange commands that calculates the product of the sentiment score and the length of each message. Arrange the results in descending order.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
#Calculate sentiment score * length of each message, create a new dataframe with mutate and arrange results in descending order
comm_data %>%
  mutate(product = sentiment*nchar(message)) %>%
  arrange(desc(product))

```
<br>

#### Question-12: Daily Message Challenge

Use the group_by, summarise, and arrange commands to find the day with the highest total number of characters sent across all messages in the "comm_data" dataframe.

**Solution:**

```{r, eval=TRUE,echo=TRUE}
# Group by days, then summarise the total number characters across all messages, then arrange 
comm_data %>% 
  group_by(date) %>%
  summarise(total_characters = sum(nchar(message))) %>%
  arrange(desc(total_characters))

```
<br>

#### Question-13: Untidy data

Can you list at least two reasons why the dataset illustrated in slide 10 is non-tidy? How can it be made Tidy?

**Solution:**  
There are multiple types of observational units are stored in the column of "Percent", where there are both percentages and full numbers not in percentage form. This can be confusing and could potentially pose as a difficulty when summarising in the future. It can be made Tidy by converting all data to percentage.  
The second reason why the dataset is non-tidy is because the variables in the columns are messy. It could be made Tidy by grouping all "unemployed" data into a single column first, followed by columns "Population 16 years and over", "Females 16 years and older", etc. 
